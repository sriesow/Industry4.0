{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# دسته بندی نهال گیاهان با استفاده از یادگیری عمیق\n### مهراد آریا \nدیتاست مورد استفاده که از یکی از مسابقات کگل با همین عنوان دریافت شده است، متشکل از یک مجموعه داده ی آموزش و مجموعه تصاویر آزمون از مراحل مختلف رشد نهال گیاهان است. هر تصویر شناسه ی یکتا و منحصر به فردی دارد. این دیتاست شامل 12 گونه ی مختلف از گیاهان است که هدف نهایی دسته بندی داده های آزمون در هر یک از این گونه هاست. بدین منظور ابتدا با متدهای پردازش تصویر به پیش پردازش و آماده سازی داده ها پرداخته سپس مدل مورد نظر را می سازیم و در نهایت کارایی آن مورد بررسی قرار می گیرد."},{"metadata":{"_uuid":"afd2c0f8328eb1633553c37a415e044a4dbd1422"},"cell_type":"markdown","source":"**1. فراخوانی ماژول های مورد نیاز:**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # MATRIX OPERATIONS\nimport pandas as pd # EFFICIENT DATA STRUCTURES\nimport matplotlib.pyplot as plt # GRAPHING AND VISUALIZATIONS\nimport math # MATHEMATICAL OPERATIONS\nimport cv2 # IMAGE PROCESSING - OPENCV\nfrom glob import glob # FILE OPERATIONS\nimport itertools # Efficient looping\n\n# KERAS AND SKLEARN MODULES\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,CSVLogger\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n# GLOBAL VARIABLES\nscale = 70 # px to scale\nseed = 7 # fixing random","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56d270d77a293192d564d774eeb3b8235415593e"},"cell_type":"markdown","source":"**2. دریافت داده ها و تغییر سایز تصاویر:**"},{"metadata":{"_uuid":"1bc9fe88c8716f1e4a0344b3c3b58b46b3ce1810","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"path_to_images = '../input/plant-seedlings-classification/train/*/*.png'\nimages = glob(path_to_images)\ntrainingset = []\ntraininglabels = []\nnum = len(images)\ncount = 1\n#READING IMAGES AND RESIZING THEM\nfor i in images:\n    print(str(count)+'/'+str(num),end='\\r')\n    # Get image (with resizing)\n    trainingset.append(cv2.resize(cv2.imread(i),(scale,scale)))\n    # Get image label (folder name)\n    traininglabels.append(i.split('/')[-2])\n    count=count+1\ntrainingset = np.asarray(trainingset) # Train images set\ntraininglabels = pd.DataFrame(traininglabels) # Train labels set","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2412c4e6d605bc9d8f35b5deb9f3dfe781bd7310","trusted":true,"collapsed":true},"cell_type":"code","source":"# Show some example images\nfor i in range(8):\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(trainingset[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ffbac53101299d45c4be2d84e25aa30c419972c"},"cell_type":"markdown","source":"**3. پاکسازی تصاویر و حذف پس زمینه:**\n* برای پیش پردازش تصاویر:\n    * تبدیل تصویر آر جی بی به اچ اس وی\n    * حذف نویز تصاویر\n    * ایجاد یک ماسک برای حذف پس زمینه\n    \n    \nبرای افزایش دقت، پس زمینه ی تصاویر را حذف میکنیم، بدین منظور از آنجایی که نهال ها غالبا به رنگ سبز یا تونالیته ای از سبز هستند ماسکی ایجاد میشود که با عمل کانوولوشن به جز بازه ای از رنگ سبز مابقی تصویر را حذف کند."},{"metadata":{"_uuid":"0969b7bdfa3614e5e7527325f63472464ca27560","trusted":true,"collapsed":true},"cell_type":"code","source":"new_train = []\nsets = []; getEx = True\nfor i in trainingset:\n        # Use gaussian blur\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n        # Convert to HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n    \n    # Create mask (parameters - green color range)\n    lower = (25,40,50)\n    upper = (75,255,255)\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n       # Create bool mask\n    boolean = mask>0\n    \n        # Apply the mask\n    new = np.zeros_like(i,np.uint8) # Create empty image\n    new[boolean] = i[boolean] # Apply boolean mask to the origin image\n    \n    new_train.append(new) # Append image without backgroung\n    \n     # Show examples\n    if getEx:\n        plt.subplot(2,3,1);plt.imshow(i) # ORIGINAL\n        plt.subplot(2,3,2);plt.imshow(blurr) # BLURRED\n        plt.subplot(2,3,3);plt.imshow(hsv) # HSV CONVERTED\n        plt.subplot(2,3,4);plt.imshow(mask) # MASKED\n        plt.subplot(2,3,5);plt.imshow(boolean) # BOOLEAN MASKED\n        plt.subplot(2,3,6);plt.imshow(new) # NEW PROCESSED IMAGE without background\n        plt.show()\n        getEx = False\nnew_train = np.asarray(new_train)\n\n\nprint('Most of the background removed:')\n    \n# Show sample result\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    plt.imshow(new_train[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12ce16ada1d5ea811b8395fffb00ab457723d28d"},"cell_type":"markdown","source":"**4. تبدیل برچسب ها به آرایه های عددی**\n* برچسب ها به صورت رشته هستند و پردازش کاراکترها سخت است، بنابرین رشته ها را به دسته های دودویی تبدیل میکنیم.\n* دسته بندی میتواند در قالب آرایه ای 12 رقمی با شرایط زیر اعمال شود:\n    * 0 - اگر گونه شناسایی نشد.\n    * 1 - اگر گونه شناسایی شد.\n* به عنوان مثال: اگر گونه ی اول یا بلک گرس تشخیص داده شد برچسب به صورت مقابل خواهد بود = [1,0,0,0,0,0,0,0,0,0,0,0]"},{"metadata":{"_uuid":"6401705a939f2f542a49b87947f7a30c46d7b64c","trusted":true,"collapsed":true},"cell_type":"code","source":"# Encode labels and create classes\nlabels = preprocessing.LabelEncoder()\nlabels.fit(traininglabels[0])\nprint('Classes: '+str(labels.classes_))\nencodedlabels = labels.transform(traininglabels[0])\n\n# Make labels categorical\nclearalllabels = np_utils.to_categorical(encodedlabels)\nclasses = clearalllabels.shape[1]\nprint(\"Number of classes: \" + str(classes))\n    \n# Plot of label types numbers\ntraininglabels[0].value_counts().plot(kind='pie')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4e446febf5983298485fd04ad7ffcc76d21dcd5"},"cell_type":"markdown","source":"**5. تعریف مدل و جداسازی دیتاست:**\n* می خواهیم بخشی از داده های آموزش را برای اعتبارسنجی یا ولیدیشن اختصاص دهیم.\n\nده درصد از داده ها به عنوان مجموعه ی اعتبارسنجی تخصیص میابد.\nداده ها به صورت نامتوازن اند، برای جلوگیری از کاهش دقت ارزیابی:"},{"metadata":{"_uuid":"8c3d89d8391f22ddf5d497295650a0b3ceaa3eb0","trusted":true,"collapsed":true},"cell_type":"code","source":"new_train = new_train/255 # Normalize input [0...255] to [0...1]\n\nx_train,x_test,y_train,y_test = train_test_split(new_train,clearalllabels,test_size=0.1,random_state=seed,stratify=clearalllabels)\nprint('Train Shape: {}'.format(x_train.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"691dab3be3969e5c091a805fada90d272f23c2ba"},"cell_type":"markdown","source":"**6. جلوگیری از بیش برازش**\n* جهت جلوگیری از بیش برازش یا آورفیتینگ تابعی طراحی میکنیم که به صورت تصادفی تغییراتی از قبیل چرخش، بزرگنمایی، شیفت و برگرداندن روی تصاویر اعمال کند و مشخصات تصویر حین برازش تغییر یابد.\n\n   * تنظیم چرخش تصادفی از 0 تا 180 درجه\n   * تنظیم بزرگنمایی تصادفی به میزان 0.1\n   * تنظیم جابجایی تصادفی به میزان 0.1\n   * تنظیم حالت آینه ی افقی و عمودی"},{"metadata":{"_uuid":"868d54609e0cdeacebbf455bf275556c8cbf1333","collapsed":true,"trusted":true},"cell_type":"code","source":"generator = ImageDataGenerator(\n    rotation_range = 180, # randomly rotate images in the range\n    zoom_range = 0.1, # Randomly zoom image \n    width_shift_range = 0.1, # randomly shift images horizontally\n    height_shift_range = 0.1, # randomly shift images vertically \n    horizontal_flip = True, # randomly flip images horizontally\n    vertical_flip = True # randomly flip images vertically\n)\ngenerator.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0792097cbb09cf07c89361b173ec7298445eb01c"},"cell_type":"markdown","source":"**7. ساخت شبکه ی عصبی کانوولوشونال**\n* این مدل 6 لایه ی کانولووشونال دارد\n* این مدل دارای 3 لایه ی چگال است\n\nبرای ایجاد این مدل از کراس استفاده شده است.\nدر ساخت شبکه ابتدا از شبکه های از پیش آموزش دیده ای چون وی جی جی 16 ، 19 و اکسپشن استفاده شد اما دقت نهایی از چیزی در حدود 85 تا 90 درصد بالاتر نرفت. سپس از 4 لایه ی کانوولوشنال و نهایتا از 6 لایه ی کانوولوشنال استفاده کردیم و در ادامه 3 لایه ی چگال فولی کانکتد به مدل اضافه شد. دو لایه ی کانوولوشنال اول 64 فیلتر و مابقی دارای 128 فیلتر هستند و دو لایه ی آخر 256 فیلتر دارند. بعد از هر جفت لایه ی کانوولوشنال مدل دارای یک لایه ی مکس پولینگ است؛ همچنین به منظور کاهش بیش برازش پس از هر جفت لایه ی کانوولوشنال از یک لایه ی دراپ آوت استفاده شده است. (10درصد بین لایه های کانوولوشنال و 50درصد بین لایه های چگال) همچنین مابین هر لایه از یک لایه ی نرمال سازی استفاده کرده ایم."},{"metadata":{"_uuid":"2c7a676c92eefbbc00d336bed3e84abc25d69d5f","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"np.random.seed(seed) # Fix seed\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(scale, scale, 3), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(classes, activation='softmax'))\n\n# compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2e7336a52c32bb79646bef1c19cb7a945df54f4"},"cell_type":"markdown","source":"**8. برازش داده ها با CNN:**\n* تعدادی کال بک طراحی میکنیم:\n    * جهت همگرایی سریع تر نرخ یادگیری باید کاهش یابد.\n    * بهترین وزن های مدل را ذخیره میکنیم.\n    * آخرین وزن های مدل را ذخیره میکنیم.  \n    \nاکنون مدل خود را آموزش میدهیم؛ ابتدا چند کال بک تنظیم میکنیم، اولی نرخ یادگیری مدل را کاهش میدهد؛ نرخ یادگیری بالا سرعت همگرایی را افزایش میدهد اما با این نرخ بالا  ممکن است مدل در مینیمم محلی گیر کند بنابرین در پروسه ی برازش نرخ یادگیری را کاهش میدهیم. نرخ کاهش میابد اگر دقت پس از سه اپوک بهبود نیابد. دو کال بک دیگر بهترین و آخرین وزن های مدل را ذخیره میکنند."},{"metadata":{"_uuid":"422cfb2de5c17a9c4a62bba978394e513556e38e","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# learning rate reduction\nlrr = ReduceLROnPlateau(monitor='val_acc', \n                        patience=3, \n                        verbose=1, \n                        factor=0.4, \n                        min_lr=0.00001)\n\n# checkpoints\nfilepath='weights.best_{epoch:02d}-{val_acc:.2f}.h5'\ncheckpoints = ModelCheckpoint(filepath, monitor='val_acc', \n                              verbose=1, save_best_only=True, mode='max')\nfilepath='weights.last_auto4.h5'\ncheckpoints_full = ModelCheckpoint(filepath, monitor='val_acc', \n                                 verbose=1, save_best_only=False, mode='max')\n\n# all callbacks\ncallbacks_list = [checkpoints, lrr, checkpoints_full]\n\n# fit model\n#hist = model.fit_generator(generator.flow(x_train, y_train, batch_size=75),\n#                            epochs=35,\n#                            validation_data=(x_test, y_test),\n#                            steps_per_epoch=x_train.shape[0],\n#                            callbacks=callbacks_list\n#                           )\n\n# Evaluate model\n# LOADING MODEL\nmodel.load_weights(\"../input/weights/weights.best_17-0.96.hdf5\") # best fitting model\ndataset = np.load(\"../input/plantrecomodels/Data.npz\") # Training and validation datasets\ndata = dict(zip((\"x_train\",\"x_test\",\"y_train\", \"y_test\"), (dataset[k] for k in dataset)))\nx_train = data['x_train']\nx_test = data['x_test']\ny_train = data['y_train']\ny_test = data['y_test']\n\nprint(model.evaluate(x_train, y_train))  # Evaluate on train set\nprint(model.evaluate(x_test, y_test))  # Evaluate on test set","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31f56b000ddbfab011358dbaf01ea90c4ef53ef1"},"cell_type":"markdown","source":"**9. ماتریس پراکندگی**\n* ماتریس پراکندگی راه مناسبی برای تشخیص خطاهای مدل است.\n* به طوری که مقدار دقیق پیش بینی های درست و نادرست را مشخص میکند."},{"metadata":{"_uuid":"d0b8fcf76d74db88e24f68eef4fa946aa1b6ff98","trusted":true,"collapsed":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    fig = plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\npredY = model.predict(x_test)\npredYClasses = np.argmax(predY, axis = 1) \ntrueY = np.argmax(y_test, axis = 1) \n\n# confusion matrix\nconfusionMTX = confusion_matrix(trueY, predYClasses) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusionMTX, classes = labels.classes_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ecd43f6947704aced8cfe27bd6d871d23c92268"},"cell_type":"markdown","source":" **10. پردازش مجموعه آزمون و پیش بینی:**"},{"metadata":{"_uuid":"71c92838dade5ea46e313061b098129809ea872a","trusted":true,"collapsed":true},"cell_type":"code","source":"path_to_test = '../input/plant-seedlings-classification/test/*.png'\npics = glob(path_to_test)\n\ntestimages = []\ntests = []\ncount=1\nnum = len(pics)\n\n# Obtain images and resizing, obtain labels\nfor i in pics:\n    print(str(count)+'/'+str(num),end='\\r')\n    tests.append(i.split('/')[-1]) # Images id's\n    testimages.append(cv2.resize(cv2.imread(i),(scale,scale)))\n    count = count + 1\n\ntestimages = np.asarray(testimages) # Train images set \n\nfor i in range(8):\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(testimages[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b8cdf25f9d8068dc96fb67cfd06ef04ecbc0d8c","trusted":true,"collapsed":true},"cell_type":"code","source":"newtestimages = []\nsets = []\ngetEx = True\nfor i in testimages:\n        # Use gaussian blur\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n        # Convert to HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n    \n        # Create mask (parameters - green color range)\n    lower = (25,40,50)\n    upper = (75,255,255)\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n        # Create bool mask\n    boolean = mask>0\n    \n        # Apply the mask\n    masking = np.zeros_like(i,np.uint8) # Create empty image\n    masking[boolean] = i[boolean] # Apply boolean mask to the origin image\n    \n    # Append image without backgroung\n    newtestimages.append(masking)\n    \n        # Show examples\n    if getEx:\n        plt.subplot(2,3,1);plt.imshow(i) # Show the original image\n        plt.subplot(2,3,2);plt.imshow(blurr) # Blur image\n        plt.subplot(2,3,3);plt.imshow(hsv) # HSV image\n        plt.subplot(2,3,4);plt.imshow(mask) # Mask\n        plt.subplot(2,3,5);plt.imshow(boolean) # Boolean mask\n        plt.subplot(2,3,6);plt.imshow(masking) # Image without background\n        plt.show()\n        getEx=False\n\nnewtestimages = np.asarray(newtestimages)\n\n# OTHER MASKED IMAGES\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.imshow(newtestimages[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e666de7b0924b4807a819de4419fa4ecd3262ba7","trusted":true,"collapsed":true},"cell_type":"code","source":"newtestimages=newtestimages/255\nprediction = model.predict(newtestimages)\n\n# Write prediction result to a file\npred = np.argmax(prediction,axis=1)\npredStr = labels.classes_[pred]\n\nresult = {'file':tests,'species':predStr}\nresult = pd.DataFrame(result)\nresult.to_csv(\"Prediction.csv\",index=False)\nprint('Prediction result saved as Prediction.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a71cb05280c5446804762fb40c57e7fd0d43527"},"cell_type":"markdown","source":"* http://www.mehradaria.com/\n*  http://www.mehrnevesht.com/"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}