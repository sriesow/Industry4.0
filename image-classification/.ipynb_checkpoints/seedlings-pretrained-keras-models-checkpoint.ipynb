{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "616f7c5b-fd90-42e3-b744-d699e42ce55b",
    "_uuid": "eed6bbd44f0d258fa2dbf0a96e7472fe77dfd9e9"
   },
   "source": [
    "# Transfer learning with pretrained Keras models\n",
    "\n",
    "Although Kernel resources were increased recently we still can not train useful CNNs without GPU. Fortunately prediction is much faster (<1s/image) making it possible to run meaningful experiments with Kaggle Kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e2dd0914-a862-4aa5-9741-433e87c63a45",
    "_uuid": "0ea36321c46ab52fa904673fe22a221b5d27c858"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "plt.rcParams['font.size'] = 16\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.applications import xception\n",
    "from keras.preprocessing import image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "deb8f726-2aa2-4a55-bda7-a5f663fb7b97",
    "_uuid": "6c1ceceae3119ef773b0611b5ab7f6613498f408",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "ee262cec-0fad-42f7-a92a-8e99c0f5e16d",
    "_uuid": "315ff18239ff7eb4ed11528e4e2ca8619b13703d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "463cad4a-17ac-4aa0-85a7-b731f06c6557",
    "_uuid": "9dad24f2b7f2cf932e36b2a5bd259ad7350961f3"
   },
   "source": [
    "# Use Keras Pretrained Models dataset\n",
    "Kernels can't use network connection to download pretrained keras model weights.\n",
    "This dataset helps you to apply your favorite pretrained model in the Kaggle Kernel environment. \n",
    "You can find more details [here](https://www.kaggle.com/gaborfodor/keras-pretrained-models).\n",
    "\n",
    "We have to copy the pretrained models to the cache directory (~/.keras/models) where keras is looking for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "73599529-b6a0-4a42-8122-6a503617a70a",
    "_uuid": "254f7813a878c36be78b279a371c8079845aa239"
   },
   "outputs": [],
   "source": [
    "!ls ../input/keras-pretrained-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b492684d-afcb-4a21-8604-50fb6905bd08",
    "_uuid": "4934928bfc41b0123fe6bd254cbf05588ae2c582",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "models_dir = os.path.join(cache_dir, 'models')\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "9f282c9d-51ed-4bee-8546-9516d1a74215",
    "_uuid": "81a1be7942ff36b8ccbcdcdf00c68d6c7b49a495",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp ../input/keras-pretrained-models/xception* ~/.keras/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "f393ca60-35f3-439b-8025-501628fd3d3e",
    "_uuid": "09d010bfbcc1589536e73d8567d2c0ed86cc2130"
   },
   "outputs": [],
   "source": [
    "!ls ~/.keras/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2d06e357-93db-42b1-895b-9a32c535ab5c",
    "_uuid": "b8120325c4c1da5f8fb388cae2cee87cb99f7a78"
   },
   "source": [
    "# Check the plant seedlings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "9652c662-852c-4fe0-921a-565a0c3b389f",
    "_uuid": "d48e3acaf4555a53dba57dc33c379c8400399430"
   },
   "outputs": [],
   "source": [
    "!ls ../input/plant-seedlings-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "14620782-c426-42b7-a567-233f194b7b7a",
    "_uuid": "c6c779c33c038bef8a3db965439a12657983d466",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n",
    "              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
    "NUM_CATEGORIES = len(CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "04d813fb-4351-4b87-9eba-1a443ddb61d6",
    "_uuid": "b688c3a5cbcbb6ed57169f845a9b80dd85c3949d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_PER_CATEGORY = 200\n",
    "SEED = 1987\n",
    "data_dir = '../input/plant-seedlings-classification/'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "sample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "d83a1778-76c4-44fe-a494-f971fee3de95",
    "_uuid": "616267c1245a074c8ad0e66d3480e648b837c375"
   },
   "outputs": [],
   "source": [
    "sample_submission.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "1f7481dc-8326-47f2-9cb4-33b6ca28ea42",
    "_uuid": "6a5300af60fd507b77a7d39d81562734e1a6e91b"
   },
   "outputs": [],
   "source": [
    "for category in CATEGORIES:\n",
    "    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "60bbddff-12f2-4690-acf0-72da1a6503a5",
    "_uuid": "fa85ae6d0f64c29d568ca697e6299eaa3b4eb556"
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "for category_id, category in enumerate(CATEGORIES):\n",
    "    for file in os.listdir(os.path.join(train_dir, category)):\n",
    "        train.append(['train/{}/{}'.format(category, file), category_id, category])\n",
    "train = pd.DataFrame(train, columns=['file', 'category_id', 'category'])\n",
    "train.head(2)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "58913b37-0e65-463d-9c48-01ed6a00b638",
    "_uuid": "949b925d64c4f50e25dc7f84a1d870e5735bc08e"
   },
   "source": [
    "# Training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "507b4a32-38b6-4dff-8714-430a1ce23342",
    "_uuid": "be192e8d9ea6d53b2d3a78bf6bdab25f662993b0"
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train[train['category'] == c][:SAMPLE_PER_CATEGORY] for c in CATEGORIES])\n",
    "train = train.sample(frac=1)\n",
    "train.index = np.arange(len(train))\n",
    "train.head(2)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "8fe2c6b8-1414-4a98-ba09-adbde64121ee",
    "_uuid": "d88f1fbcdd4ddb777435ce1f27996f4fb69d089a"
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "for file in os.listdir(test_dir):\n",
    "    test.append(['test/{}'.format(file), file])\n",
    "test = pd.DataFrame(test, columns=['filepath', 'file'])\n",
    "test.head(2)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "2662f1a2-1930-49bd-85cd-e36a59b3dd9b",
    "_uuid": "a17ad0110424e8545fa73c1f3988ccc1ec9598f9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_img(filepath, size):\n",
    "    img = image.load_img(os.path.join(data_dir, filepath), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e13db656-a9be-4ed2-b24b-bd504344c6ab",
    "_uuid": "b21a709045cfd96227a2f1c7e258741347bc39d7"
   },
   "source": [
    "# Example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "f444d98e-b6b2-4e81-a1cd-6a0b9cf1d5c4",
    "_uuid": "d41dd29a0c62d1cca4ee82ac234e95cfb32cc6ab"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(NUM_CATEGORIES, NUM_CATEGORIES))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(NUM_CATEGORIES, NUM_CATEGORIES), axes_pad=0.05)\n",
    "i = 0\n",
    "for category_id, category in enumerate(CATEGORIES):\n",
    "    for filepath in train[train['category'] == category]['file'].values[:NUM_CATEGORIES]:\n",
    "        ax = grid[i]\n",
    "        img = read_img(filepath, (224, 224))\n",
    "        ax.imshow(img / 255.)\n",
    "        ax.axis('off')\n",
    "        if i % NUM_CATEGORIES == NUM_CATEGORIES - 1:\n",
    "            ax.text(250, 112, filepath.split('/')[1], verticalalignment='center')\n",
    "        i += 1\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8ea7a715-c3ca-4f4d-999b-9659eaa5a1e3",
    "_uuid": "1c93527fe50e1b91e9d9d2be905500d96bf7f76b"
   },
   "source": [
    "# Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "ced5450c-7ce8-4405-b34d-bf37eb38e0b3",
    "_uuid": "7f2c46099d0f7555e923d3ca4e7b112d68dd51cf"
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=SEED)\n",
    "rnd = np.random.random(len(train))\n",
    "train_idx = rnd < 0.8\n",
    "valid_idx = rnd >= 0.8\n",
    "ytr = train.loc[train_idx, 'category_id'].values\n",
    "yv = train.loc[valid_idx, 'category_id'].values\n",
    "len(ytr), len(yv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "140b509f-94ad-4f64-96d0-f76ef299ef1a",
    "_uuid": "fc2e809d03bfc8195b1d02f2b765515effa01bbb"
   },
   "source": [
    "## Extract Xception bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "7152595a-bc0e-4c1e-9945-b63ecbd695dd",
    "_uuid": "f3f59af75a0ad4f667064f50e0356cf2b1447f19"
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 299\n",
    "POOLING = 'avg'\n",
    "x_train = np.zeros((len(train), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, file in tqdm(enumerate(train['file'])):\n",
    "    img = read_img(file, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "910da5f0-74ce-4ca1-b817-0bd576c8876c",
    "_uuid": "6d5f2aea4581170e2498e8127f35e44c7e3550d8"
   },
   "outputs": [],
   "source": [
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "print((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\n",
    "xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "valid_x_bf = xception_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "print('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\n",
    "print('Xception valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed155341-c762-4257-b22c-50cb26d1e0dc",
    "_uuid": "26e3a6e3383fcfc85b2cf02ae35709d69a21d1ae"
   },
   "source": [
    "## LogReg on Xception bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "1b619668-b540-407a-b478-42eb55526c32",
    "_uuid": "105b5bb8a0c7f085ba640684c61b963b09e57d3b"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(train_x_bf, ytr)\n",
    "valid_probs = logreg.predict_proba(valid_x_bf)\n",
    "valid_preds = logreg.predict(valid_x_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "6a8e4c54-f4a3-406c-9bdb-79b8d68f9778",
    "_uuid": "2672c5978efb2e56921c44ad38986fde2d6c0661"
   },
   "outputs": [],
   "source": [
    "print('Validation Xception Accuracy {}'.format(accuracy_score(yv, valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "520f241f-4ac2-4ffd-9200-ebb7067c6c19",
    "_uuid": "1907b6d61dea447b6292247b526e65430a9272c7"
   },
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "bee3a60d-47cc-4c99-bac1-ae995d36a44f",
    "_uuid": "296af537c2f84893baf57e2838cc58a06fe514de",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(yv, valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "4a502dbf-0451-4a2c-bd6a-36942d2c9b40",
    "_uuid": "26d7c4fcfd7a5b3402cd2619ff4f6375a708e5fb"
   },
   "outputs": [],
   "source": [
    "abbreviation = ['BG', 'Ch', 'Cl', 'CC', 'CW', 'FH', 'LSB', 'M', 'SM', 'SP', 'SFC', 'SB']\n",
    "pd.DataFrame({'class': CATEGORIES, 'abbreviation': abbreviation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "abb70092-d085-4ee4-bee9-f36345d252a1",
    "_uuid": "01c7ed4b0384db2ed9f5f904112a63c4210386e8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax = sns.heatmap(cnf_matrix, ax=ax, cmap=plt.cm.Greens, annot=True)\n",
    "ax.set_xticklabels(abbreviation)\n",
    "ax.set_yticklabels(abbreviation)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "fig.savefig('Confusion matrix.png', dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78241212-ebfe-453f-abd3-98c8b8362b91",
    "_uuid": "bd6591ab1070226352dba8eea2619b13a625d023"
   },
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "d94b2d0d-3a48-4502-a74c-c919236bbd94",
    "_uuid": "3286a8262ed80b2cd7fcecea4138b2c15de08197"
   },
   "outputs": [],
   "source": [
    "x_test = np.zeros((len(test), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, filepath in tqdm(enumerate(test['filepath'])):\n",
    "    img = read_img(filepath, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_test[i] = x\n",
    "print('test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "6218510d-9efe-4935-a9f3-468b71127298",
    "_uuid": "67305f8cda58943a437b9e029351692f44ac339c"
   },
   "outputs": [],
   "source": [
    "test_x_bf = xception_bottleneck.predict(x_test, batch_size=32, verbose=1)\n",
    "print('Xception test bottleneck features shape: {} size: {:,}'.format(test_x_bf.shape, test_x_bf.size))\n",
    "test_preds = logreg.predict(test_x_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "0bffccab-cb6b-4e85-9d9f-746d22843509",
    "_uuid": "ac7c62255748e3ca80c5424da9de54dcf12da463",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['category_id'] = test_preds\n",
    "test['species'] = [CATEGORIES[c] for c in test_preds]\n",
    "test[['file', 'species']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "debc53f3-9454-4b48-9961-e5663db49167",
    "_uuid": "65220cc1537f74448fba07284f0a8befa8cddb5e"
   },
   "outputs": [],
   "source": [
    "end = dt.datetime.now()\n",
    "print('Total time {} s.'.format((end - start).seconds))\n",
    "print('We almost used the one hour time limit.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
